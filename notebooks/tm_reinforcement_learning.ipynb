{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:12:44.457193Z",
     "start_time": "2020-12-16T16:12:44.411811Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:12:58.798805Z",
     "start_time": "2020-12-16T16:12:44.848777Z"
    }
   },
   "outputs": [],
   "source": [
    "train_1M= pd.read_csv('../data/train_1M_with_features_merged_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:12:58.858106Z",
     "start_time": "2020-12-16T16:12:58.814857Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'row_id', 'timestamp', 'user_id', 'content_id',\n",
       "       'content_type_id', 'task_container_id', 'answered_correctly',\n",
       "       'prior_question_elapsed_time', 'prior_question_had_explanation',\n",
       "       'answer0', 'answer1', 'answer2', 'answer3', 'user_activity_cumcount',\n",
       "       'already_seen', 'lectures_seen', 'at_least_one_lesson',\n",
       "       'user_avg_score_cum', 'qstats_answered_correctly', 'qstats_count',\n",
       "       'qstats_task_container_id', 'qstats_answers', 'qstats_timestamp',\n",
       "       'qstats_user_activity_cumcount',\n",
       "       'qstats_prior_question_had_explanation',\n",
       "       'qstats_prior_question_elapsed_time', 'qstats_answer0',\n",
       "       'qstats_answer1', 'qstats_answer2', 'qstats_answer3',\n",
       "       'qstats_answered_correctly_knowing_having_had_explanation',\n",
       "       'qstats_answered_correctly_knowing_having_not_had_explanation',\n",
       "       'qstats_task_container_id_knowing_answered_correctly',\n",
       "       'qstats_timestamp_knowing_answered_correctly',\n",
       "       'qstats_user_activity_cumcount_knowing_answered_correctly',\n",
       "       'qstats_prior_question_elapsed_time_knowing_answered_correctly',\n",
       "       'qstats_task_container_id_knowing_answered_uncorrectly',\n",
       "       'qstats_timestamp_knowing_answered_uncorrectly',\n",
       "       'qstats_user_activity_cumcount_knowing_answered_uncorrectly',\n",
       "       'qstats_prior_question_elapsed_time_knowing_answered_uncorrectly',\n",
       "       'user_personalized_qstat_knowing_had_explanation_or_not', 'tag_q_l',\n",
       "       'part_q_l', 'section', 'cumcount_already_seen_tag_q_l',\n",
       "       'already_seen_tag_lecture', 'already_seen_part',\n",
       "       'user_avg_score_cum_on_this_part',\n",
       "       'user_correct_answers_cum_on_this_part', 'part1', 'part2', 'part3',\n",
       "       'part4', 'part5', 'part6', 'part7',\n",
       "       'already_seen_tag_q_l_cumcount_with_trim_at_3',\n",
       "       'same_user_and_similar_to_prior',\n",
       "       'similar_to_prior_and_had_answered_correctly',\n",
       "       'similar_to_prior_and_have_had_explanation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1M.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T16:12:59.198553Z",
     "start_time": "2020-12-16T16:12:58.869084Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "my_pipeline = pickle.load(open('../models/xgboost_pipe_M1.pkl',\"rb\"))  ## wb= write bites : le b est important\n",
    "qstats=pd.read_csv('../data/qstats_for_M1')\n",
    "pipeline_features_list=pd.read_csv('../models/xgboost_pipe_M1_features_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions déjà définies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T15:45:22.223280Z",
     "start_time": "2020-12-16T15:45:22.103320Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_history_update(content_type_id,\n",
    "                        content_id,\n",
    "                        data_qstats,\n",
    "                        user_history=None,\n",
    "                        mode='training',    #autre choix : mode exam\n",
    "                        prior_question_had_explanation=False):\n",
    "    '''Crée ou met à jour l'hisorique d'un utilisateur, stockée dans un df'''\n",
    "\n",
    "    if not type(user_history)==pd.DataFrame:\n",
    "        user_history=pd.DataFrame({\n",
    "                             #following columns are the impute of each loop\n",
    "                             ### TO BE IMPUTED ###\n",
    "                             'content_id':[-1],\n",
    "                             'content_type_id':[-1],\n",
    "                             'prior_question_had_explanation':False,\n",
    "                             'mode':'n/a',\n",
    "                             # following columns depend of previous history of the user : \n",
    "                             ### TO BE UPDATED WHATEVER THE CONTENT_TYPE ###\n",
    "                             'user_activity_cumcount':[-1],\n",
    "                             ### TO BE UPDATED IF LAST WAS LECTURE ###\n",
    "                             'at_least_one_lesson':[0],\n",
    "                             ### TO BE UPDATED IF LAST WAS QUESTION ###\n",
    "                             'user_avg_score_cum':[0.499],\n",
    "                             'user_correct_answers_cum':[0],\n",
    "                             'user_avg_score_cum_part1':[0.499],\n",
    "                             'user_avg_score_cum_part2':[0.499],\n",
    "                             'user_avg_score_cum_part3':[0.499],\n",
    "                             'user_avg_score_cum_part4':[0.499],\n",
    "                             'user_avg_score_cum_part5':[0.499],\n",
    "                             'user_avg_score_cum_part6':[0.499],\n",
    "                             'user_avg_score_cum_part7':[0.499],\n",
    "                             'user_correct_answers_cum_part1':[0],\n",
    "                             'user_correct_answers_cum_part2':[0],\n",
    "                             'user_correct_answers_cum_part3':[0],\n",
    "                             'user_correct_answers_cum_part4':[0],\n",
    "                             'user_correct_answers_cum_part5':[0],\n",
    "                             'user_correct_answers_cum_part6':[0],\n",
    "                             'user_correct_answers_cum_part7':[0],\n",
    "                             # following columns are pure question stats : \n",
    "                             ### TO BE IMPORTED FROM QUESTIONS ###\n",
    "                             'part':[-1],\n",
    "                             'qstats_answered_correctly':[-1],\n",
    "                             'qstats_prior_question_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_not_had_explanation':[-1],\n",
    "                             # following columns depend of the current question AND the hisory of user\n",
    "                             ### TO BE COMPUTED ###\n",
    "                             'user_personalized_qstat_knowing_had_explanation_or_not':[-1],\n",
    "                             'already_seen':[-1],\n",
    "                             'user_avg_score_cum_on_this_part':[-1],\n",
    "                             'user_correct_answers_cum_on_this_part':[-1],\n",
    "                             # the following line is the prediction to be made\n",
    "                             ### TO BE PREDICTED ###\n",
    "                             'answered_correctly':[-1]\n",
    "                          })\n",
    "    \n",
    "\n",
    "    last_line=user_history.iloc[-1]\n",
    "    new_line =last_line.copy()\n",
    "    \n",
    "    last_content_type_id=user_history.iloc[-1]['content_type_id']\n",
    "    \n",
    "    ### TO BE IMPUTED ###\n",
    "    new_line['content_id']=content_id\n",
    "    new_line['content_type_id']=content_type_id\n",
    "    new_line['prior_question_had_explanation']=prior_question_had_explanation\n",
    "    new_line['mode']=mode\n",
    "    ### TO BE UPDATED WHATEVER THE CONTENT_TYPE ###\n",
    "    new_line['user_activity_cumcount'] += 1\n",
    "    \n",
    "    if mode=='training':\n",
    "        if last_content_type_id==0:\n",
    "            part=last_line['part']\n",
    "            ### TO BE UPDATED IF LAST WAS QUESTION ###\n",
    "            new_line['user_correct_answers_cum'] = last_line['user_correct_answers_cum']\\\n",
    "                                                 + last_line['answered_correctly']\n",
    "            new_user_questions_count             = last_line['user_correct_answers_cum']\\\n",
    "                                                 / last_line['user_avg_score_cum']\\\n",
    "                                                 + 1\n",
    "            new_line['user_avg_score_cum']       = new_line['user_correct_answers_cum']\\\n",
    "                                                 / new_user_questions_count\n",
    "\n",
    "            new_line[f'user_correct_answers_cum_part{part}'] = last_line[f'user_correct_answers_cum_part{part}']\\\n",
    "                                                             + last_line['answered_correctly']\n",
    "            vars()[f'new_user_questions_count_part{part}']   = last_line[f'user_correct_answers_cum_part{part}']\\\n",
    "                                                             / last_line[f'user_avg_score_cum_part{part}']\\\n",
    "                                                             + 1\n",
    "            new_line[f'user_avg_score_cum_part{part}']       = new_line[f'user_correct_answers_cum_part{part}']\\\n",
    "                                                             / vars()[f'new_user_questions_count_part{part}']\n",
    "\n",
    "        elif last_content_type_id==1:\n",
    "            ### TO BE UPDATED IF LAST WAS LECTURE ###\n",
    "            new_line['at_least_one_lesson']=1\n",
    "        \n",
    "    if content_type_id==0: \n",
    "        currect_question_stats=qstats.loc[qstats.content_id==content_id].iloc[-1]\n",
    "        ### TO BE IMPORTED FROM QUESTIONS ###\n",
    "        new_line['part']\\\n",
    "              = currect_question_stats['part']\n",
    "        new_line['qstats_answered_correctly']\\\n",
    "              = currect_question_stats['qstats_answered_correctly']\n",
    "        new_line['qstats_prior_question_had_explanation']\\\n",
    "              = currect_question_stats['qstats_prior_question_had_explanation']\n",
    "        new_line['qstats_answered_correctly_knowing_having_had_explanation']\\\n",
    "              = currect_question_stats['qstats_answered_correctly_knowing_having_had_explanation']\n",
    "        new_line['qstats_answered_correctly_knowing_having_not_had_explanation']\\\n",
    "              = currect_question_stats['qstats_answered_correctly_knowing_having_not_had_explanation']\n",
    "        ### TO BE COMPUTED ###\n",
    "        new_line['user_personalized_qstat_knowing_had_explanation_or_not']\\\n",
    "              = new_line['qstats_answered_correctly_knowing_having_had_explanation']\\\n",
    "             if prior_question_had_explanation\\\n",
    "           else new_line['qstats_answered_correctly_knowing_having_not_had_explanation']\n",
    "        new_line['already_seen']\\\n",
    "              = 1 if content_id in user_history.loc[user_history.content_type_id==0,'content_id']\\\n",
    "           else 0\n",
    "        new_line['user_avg_score_cum_on_this_part']=new_line[f'user_avg_score_cum_part{new_line[\"part\"]}']\n",
    "        new_line['user_correct_answers_cum_on_this_part']=new_line[f'user_correct_answers_cum_part{new_line[\"part\"]}']\n",
    "                                              \n",
    "    elif content_type_id==1:\n",
    "        \n",
    "        ### TO BE IMPORTED ###\n",
    "        new_line['part']= -1 # TODO : si on veut utiliser la partie de la lecture, il faut importer la base des lectures\n",
    "        new_line['qstats_answered_correctly']= -1\n",
    "        new_line['qstats_prior_question_had_explanation']= -1\n",
    "        new_line['qstats_answered_correctly_knowing_having_had_explanation']= -1\n",
    "        new_line['qstats_answered_correctly_knowing_having_not_had_explanation']= -1\n",
    "        ### TO BE COMPUTED ###\n",
    "        new_line['user_personalized_qstat_knowing_had_explanation_or_not']= -1\n",
    "        new_line['already_seen']= -1\n",
    "        new_line['user_avg_score_cum_on_this_part']= -1\n",
    "        new_line['user_correct_answers_cum_on_this_part']= -1\n",
    "        \n",
    "    ### TO BE PREDICTED ###\n",
    "    new_line['answered_correctly']= -1\n",
    "                                \n",
    "    user_history=user_history.append(new_line,ignore_index=True)\n",
    "\n",
    "    return user_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T13:31:53.157660Z",
     "start_time": "2020-12-16T13:31:53.148513Z"
    }
   },
   "outputs": [],
   "source": [
    "def training (qstats, user_history=None, loop_length=30, question_selection_strategy='random'):\n",
    "    for i in range(loop_length):\n",
    "        ### CHOIX DE LA QUESTION ###\n",
    "        if question_selection_strategy=='random':\n",
    "            next_question_id=random.choice(qstats.content_id.to_list())\n",
    "\n",
    "\n",
    "            user_history=user_history_update(0,\n",
    "                                         next_question_id,\n",
    "                                         qstats,\n",
    "                                         user_history,\n",
    "                                         mode='training',\n",
    "                                         prior_question_had_explanation=random.uniform(0, 1)>0.1)\n",
    "\n",
    "        ### PREDICTION ###\n",
    "            user_history.iloc[-1,-1]\\\n",
    "                = my_pipeline.predict_proba(user_history[pipeline_features_list.feature.to_list()].iloc[-2:-1])[0,1]\n",
    "    return user_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T13:31:54.255745Z",
     "start_time": "2020-12-16T13:31:54.246259Z"
    }
   },
   "outputs": [],
   "source": [
    "def TOEIC_scoring (qstats, user_history, number_of_questions=100, TOEIC_strategy='random'):\n",
    "    for i in range(number_of_questions):\n",
    "        ### CHOIX DE LA QUESTION ###\n",
    "        if TOEIC_strategy=='random':\n",
    "            next_question_id=random.choice(qstats.content_id.to_list())\n",
    "\n",
    "\n",
    "        user_history=user_history_update(0,\n",
    "                                         next_question_id,\n",
    "                                         qstats,\n",
    "                                         user_history,\n",
    "                                         mode='exam',\n",
    "                                         prior_question_had_explanation=False)\n",
    "\n",
    "        ### PREDICTION ###\n",
    "        user_history.iloc[-1,-1]\\\n",
    "            = my_pipeline.predict_proba(user_history[pipeline_features_list.feature.to_list()].iloc[-2:-1])[0,1]\n",
    "    \n",
    "    return user_history.iloc[-number_of_questions:].answered_correctly.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:33:25.085056Z",
     "start_time": "2020-12-16T14:33:25.014876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 8845 to 8267\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                                        Non-Null Count  Dtype  \n",
      "---  ------                                                        --------------  -----  \n",
      " 0   content_id                                                    100 non-null    int64  \n",
      " 1   correct_answer                                                100 non-null    int64  \n",
      " 2   part                                                          100 non-null    int64  \n",
      " 3   tags                                                          100 non-null    object \n",
      " 4   qstats_count                                                  100 non-null    int64  \n",
      " 5   qstats_answered_correctly                                     100 non-null    float64\n",
      " 6   qstats_prior_question_had_explanation                         100 non-null    float64\n",
      " 7   qstats_answered_correctly_knowing_having_had_explanation      100 non-null    float64\n",
      " 8   qstats_answered_correctly_knowing_having_not_had_explanation  100 non-null    float64\n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 7.8+ KB\n"
     ]
    }
   ],
   "source": [
    "q_sample_100=qstats.sample(n=100).drop(columns=['Unnamed: 0','bundle_id'])\n",
    "print(q_sample_100.shape)\n",
    "q_sample_100.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:33:42.540732Z",
     "start_time": "2020-12-16T14:33:42.492932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>qstats_count</th>\n",
       "      <th>qstats_answered_correctly</th>\n",
       "      <th>qstats_prior_question_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_not_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>8845</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>4538</td>\n",
       "      <td>0.806523</td>\n",
       "      <td>0.993169</td>\n",
       "      <td>0.806523</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9822</th>\n",
       "      <td>9822</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>7291</td>\n",
       "      <td>0.291318</td>\n",
       "      <td>0.991496</td>\n",
       "      <td>0.291742</td>\n",
       "      <td>0.241935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>9718</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>3285</td>\n",
       "      <td>0.571994</td>\n",
       "      <td>0.974125</td>\n",
       "      <td>0.576562</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>7429</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>98 84 97 87 122 162</td>\n",
       "      <td>5356</td>\n",
       "      <td>0.755788</td>\n",
       "      <td>0.941748</td>\n",
       "      <td>0.755551</td>\n",
       "      <td>0.759615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>6989</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>145 77 42 35 122</td>\n",
       "      <td>10954</td>\n",
       "      <td>0.854117</td>\n",
       "      <td>0.955998</td>\n",
       "      <td>0.852368</td>\n",
       "      <td>0.892116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>6026</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>3344</td>\n",
       "      <td>0.742524</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.747922</td>\n",
       "      <td>0.557895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>1795</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>157 38 81</td>\n",
       "      <td>5198</td>\n",
       "      <td>0.783955</td>\n",
       "      <td>0.966141</td>\n",
       "      <td>0.784349</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>3567</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.745289</td>\n",
       "      <td>0.962313</td>\n",
       "      <td>0.753545</td>\n",
       "      <td>0.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>2612</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>136 144 162 92</td>\n",
       "      <td>6054</td>\n",
       "      <td>0.693095</td>\n",
       "      <td>0.971424</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>0.757225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1867</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>157 81 92</td>\n",
       "      <td>12675</td>\n",
       "      <td>0.482604</td>\n",
       "      <td>0.965365</td>\n",
       "      <td>0.481693</td>\n",
       "      <td>0.507973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12284</th>\n",
       "      <td>12284</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>82 38 29</td>\n",
       "      <td>269</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.973978</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12537</th>\n",
       "      <td>12537</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>106 38 59</td>\n",
       "      <td>219</td>\n",
       "      <td>0.689498</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9350</th>\n",
       "      <td>9350</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>4591</td>\n",
       "      <td>0.755609</td>\n",
       "      <td>0.969506</td>\n",
       "      <td>0.762975</td>\n",
       "      <td>0.521429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>6083</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>15338</td>\n",
       "      <td>0.428935</td>\n",
       "      <td>0.982136</td>\n",
       "      <td>0.430696</td>\n",
       "      <td>0.332117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>5793</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>9959</td>\n",
       "      <td>0.782207</td>\n",
       "      <td>0.970579</td>\n",
       "      <td>0.784399</td>\n",
       "      <td>0.709898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10637</th>\n",
       "      <td>10637</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 99 92</td>\n",
       "      <td>6191</td>\n",
       "      <td>0.884671</td>\n",
       "      <td>0.986916</td>\n",
       "      <td>0.885106</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10725</th>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>106 92 3</td>\n",
       "      <td>9003</td>\n",
       "      <td>0.843719</td>\n",
       "      <td>0.973009</td>\n",
       "      <td>0.843836</td>\n",
       "      <td>0.839506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>12177</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155 163 81 92</td>\n",
       "      <td>1509</td>\n",
       "      <td>0.774023</td>\n",
       "      <td>0.994036</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>12217</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>143 114 38 29</td>\n",
       "      <td>1485</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.995960</td>\n",
       "      <td>0.925625</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12586</th>\n",
       "      <td>12586</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 99 81</td>\n",
       "      <td>147</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.815068</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>2870</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>157 103 38</td>\n",
       "      <td>5230</td>\n",
       "      <td>0.757553</td>\n",
       "      <td>0.966922</td>\n",
       "      <td>0.756377</td>\n",
       "      <td>0.791908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>1767</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>136 38 29 102</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.747733</td>\n",
       "      <td>0.968667</td>\n",
       "      <td>0.746456</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>155 119 162 38 92</td>\n",
       "      <td>9950</td>\n",
       "      <td>0.873869</td>\n",
       "      <td>0.980603</td>\n",
       "      <td>0.874347</td>\n",
       "      <td>0.849741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>7665</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>97 160 16 35 122 162</td>\n",
       "      <td>5445</td>\n",
       "      <td>0.222039</td>\n",
       "      <td>0.960882</td>\n",
       "      <td>0.224388</td>\n",
       "      <td>0.164319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1136</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>137 88 38 92</td>\n",
       "      <td>11443</td>\n",
       "      <td>0.720703</td>\n",
       "      <td>0.983746</td>\n",
       "      <td>0.722217</td>\n",
       "      <td>0.629032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>6046</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>20110</td>\n",
       "      <td>0.761959</td>\n",
       "      <td>0.982297</td>\n",
       "      <td>0.763390</td>\n",
       "      <td>0.682584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>143 141 38 29</td>\n",
       "      <td>93</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>3552</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2129</td>\n",
       "      <td>0.760451</td>\n",
       "      <td>0.968530</td>\n",
       "      <td>0.760912</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>2577</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>161 103 102</td>\n",
       "      <td>11506</td>\n",
       "      <td>0.832609</td>\n",
       "      <td>0.966105</td>\n",
       "      <td>0.833033</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10578</th>\n",
       "      <td>10578</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 5 102</td>\n",
       "      <td>5701</td>\n",
       "      <td>0.953342</td>\n",
       "      <td>0.988774</td>\n",
       "      <td>0.952989</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>4641</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>3683</td>\n",
       "      <td>0.757806</td>\n",
       "      <td>0.974749</td>\n",
       "      <td>0.762117</td>\n",
       "      <td>0.591398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9195</th>\n",
       "      <td>9195</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>4723</td>\n",
       "      <td>0.476816</td>\n",
       "      <td>0.996612</td>\n",
       "      <td>0.477162</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9007</th>\n",
       "      <td>9007</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5001</td>\n",
       "      <td>0.621876</td>\n",
       "      <td>0.917017</td>\n",
       "      <td>0.637593</td>\n",
       "      <td>0.448193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>143 176 92 29</td>\n",
       "      <td>7098</td>\n",
       "      <td>0.882502</td>\n",
       "      <td>0.980417</td>\n",
       "      <td>0.882598</td>\n",
       "      <td>0.877698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>2926</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>136 171 162 102</td>\n",
       "      <td>260</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>3696</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>6719</td>\n",
       "      <td>0.749814</td>\n",
       "      <td>0.983331</td>\n",
       "      <td>0.750719</td>\n",
       "      <td>0.696429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8103</th>\n",
       "      <td>8103</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>84 50 18 135</td>\n",
       "      <td>80</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>5947</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3273</td>\n",
       "      <td>0.744577</td>\n",
       "      <td>0.974947</td>\n",
       "      <td>0.749922</td>\n",
       "      <td>0.536585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>6319</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>5582</td>\n",
       "      <td>0.739699</td>\n",
       "      <td>0.977965</td>\n",
       "      <td>0.739146</td>\n",
       "      <td>0.764228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>4351</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>219</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>74 92 29</td>\n",
       "      <td>5842</td>\n",
       "      <td>0.794591</td>\n",
       "      <td>0.967306</td>\n",
       "      <td>0.795081</td>\n",
       "      <td>0.780105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>11540</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1372</td>\n",
       "      <td>0.628280</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.628196</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>674</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>143 30 81 92</td>\n",
       "      <td>126</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4908</th>\n",
       "      <td>4908</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2572</td>\n",
       "      <td>0.536547</td>\n",
       "      <td>0.537714</td>\n",
       "      <td>0.599422</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>155 163 38 102</td>\n",
       "      <td>20329</td>\n",
       "      <td>0.580993</td>\n",
       "      <td>0.920409</td>\n",
       "      <td>0.596066</td>\n",
       "      <td>0.406675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>1571</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>74 92 29 102</td>\n",
       "      <td>11044</td>\n",
       "      <td>0.633828</td>\n",
       "      <td>0.964234</td>\n",
       "      <td>0.632454</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11509</th>\n",
       "      <td>11509</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>1456</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.996566</td>\n",
       "      <td>0.928325</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1216</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>143 140 92 102</td>\n",
       "      <td>8365</td>\n",
       "      <td>0.893604</td>\n",
       "      <td>0.975971</td>\n",
       "      <td>0.895884</td>\n",
       "      <td>0.800995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>4404</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.752665</td>\n",
       "      <td>0.969477</td>\n",
       "      <td>0.752874</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>3849</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>4156</td>\n",
       "      <td>0.862608</td>\n",
       "      <td>0.939605</td>\n",
       "      <td>0.869910</td>\n",
       "      <td>0.749004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13357</th>\n",
       "      <td>13357</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>832</td>\n",
       "      <td>0.817308</td>\n",
       "      <td>0.996394</td>\n",
       "      <td>0.816647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1390</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>143 140 92 29</td>\n",
       "      <td>7725</td>\n",
       "      <td>0.859935</td>\n",
       "      <td>0.974369</td>\n",
       "      <td>0.861565</td>\n",
       "      <td>0.797980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>10688</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62 137 142 81 92</td>\n",
       "      <td>126998</td>\n",
       "      <td>0.778705</td>\n",
       "      <td>0.996748</td>\n",
       "      <td>0.778868</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9886</th>\n",
       "      <td>9886</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.751531</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.751979</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>10265</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>4661</td>\n",
       "      <td>0.863120</td>\n",
       "      <td>0.958593</td>\n",
       "      <td>0.859669</td>\n",
       "      <td>0.943005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>4586</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>981</td>\n",
       "      <td>0.909276</td>\n",
       "      <td>0.934760</td>\n",
       "      <td>0.907306</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>62 138 41 162 92 102</td>\n",
       "      <td>13337</td>\n",
       "      <td>0.739597</td>\n",
       "      <td>0.981030</td>\n",
       "      <td>0.742204</td>\n",
       "      <td>0.604743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10 70 162 81</td>\n",
       "      <td>978</td>\n",
       "      <td>0.933538</td>\n",
       "      <td>0.971370</td>\n",
       "      <td>0.934737</td>\n",
       "      <td>0.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>6335</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>4766</td>\n",
       "      <td>0.843894</td>\n",
       "      <td>0.976081</td>\n",
       "      <td>0.844153</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>3801</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1845</td>\n",
       "      <td>0.800542</td>\n",
       "      <td>0.917073</td>\n",
       "      <td>0.809693</td>\n",
       "      <td>0.699346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       content_id  correct_answer  part                  tags  qstats_count  \\\n",
       "8845         8845               2     5                    53          4538   \n",
       "9822         9822               2     5                    96          7291   \n",
       "9718         9718               1     5                    55          3285   \n",
       "7429         7429               0     7   98 84 97 87 122 162          5356   \n",
       "6989         6989               2     7      145 77 42 35 122         10954   \n",
       "6026         6026               3     5                   173          3344   \n",
       "1795         1795               2     3             157 38 81          5198   \n",
       "3567         3567               0     5                     8          1539   \n",
       "2612         2612               0     4        136 144 162 92          6054   \n",
       "1867         1867               1     3             157 81 92         12675   \n",
       "12284       12284               1     3              82 38 29           269   \n",
       "12537       12537               2     4             106 38 59           219   \n",
       "9350         9350               3     5                    53          4591   \n",
       "6083         6083               3     5                    48         15338   \n",
       "5793         5793               0     5                    66          9959   \n",
       "10637       10637               0     1             131 99 92          6191   \n",
       "10725       10725               0     4              106 92 3          9003   \n",
       "12177       12177               0     2         155 163 81 92          1509   \n",
       "12217       12217               1     2         143 114 38 29          1485   \n",
       "12586       12586               0     1             131 99 81           147   \n",
       "2870         2870               1     4            157 103 38          5230   \n",
       "1767         1767               3     3         136 38 29 102          7500   \n",
       "1005         1005               3     2     155 119 162 38 92          9950   \n",
       "7665         7665               3     7  97 160 16 35 122 162          5445   \n",
       "1136         1136               0     2          137 88 38 92         11443   \n",
       "6046         6046               3     5                   147         20110   \n",
       "799           799               3     2         143 141 38 29            93   \n",
       "3552         3552               1     5                     8          2129   \n",
       "2577         2577               3     4           161 103 102         11506   \n",
       "10578       10578               0     1             131 5 102          5701   \n",
       "4641         4641               3     5                    79          3683   \n",
       "9195         9195               2     5                    96          4723   \n",
       "9007         9007               3     5                     1          5001   \n",
       "356           356               0     2         143 176 92 29          7098   \n",
       "2926         2926               3     4       136 171 162 102           260   \n",
       "3696         3696               0     5                   109          6719   \n",
       "8103         8103               3     7          84 50 18 135            80   \n",
       "5947         5947               1     5                    14          3273   \n",
       "6319         6319               1     5                    53          5582   \n",
       "4351         4351               3     5                    89           219   \n",
       "2156         2156               2     3              74 92 29          5842   \n",
       "11540       11540               2     5                    96          1372   \n",
       "674           674               1     2          143 30 81 92           126   \n",
       "4908         4908               0     5                     8          2572   \n",
       "386           386               1     2        155 163 38 102         20329   \n",
       "1571         1571               3     3          74 92 29 102         11044   \n",
       "11509       11509               3     5                   116          1456   \n",
       "1216         1216               1     2        143 140 92 102          8365   \n",
       "4404         4404               2     5                    14          4128   \n",
       "3849         3849               1     5                    89          4156   \n",
       "13357       13357               3     5                    96           832   \n",
       "1390         1390               0     2         143 140 92 29          7725   \n",
       "10688       10688               0     2      62 137 142 81 92        126998   \n",
       "9886         9886               0     5                     1          4572   \n",
       "10265       10265               2     6                    53          4661   \n",
       "4586         4586               1     5                    79           981   \n",
       "328           328               1     2  62 138 41 162 92 102         13337   \n",
       "137           137               3     1          10 70 162 81           978   \n",
       "6335         6335               0     5                    53          4766   \n",
       "3801         3801               0     5                     8          1845   \n",
       "\n",
       "       qstats_answered_correctly  qstats_prior_question_had_explanation  \\\n",
       "8845                    0.806523                               0.993169   \n",
       "9822                    0.291318                               0.991496   \n",
       "9718                    0.571994                               0.974125   \n",
       "7429                    0.755788                               0.941748   \n",
       "6989                    0.854117                               0.955998   \n",
       "6026                    0.742524                               0.971591   \n",
       "1795                    0.783955                               0.966141   \n",
       "3567                    0.745289                               0.962313   \n",
       "2612                    0.693095                               0.971424   \n",
       "1867                    0.482604                               0.965365   \n",
       "12284                   0.940520                               0.973978   \n",
       "12537                   0.689498                               0.968037   \n",
       "9350                    0.755609                               0.969506   \n",
       "6083                    0.428935                               0.982136   \n",
       "5793                    0.782207                               0.970579   \n",
       "10637                   0.884671                               0.986916   \n",
       "10725                   0.843719                               0.973009   \n",
       "12177                   0.774023                               0.994036   \n",
       "12217                   0.925926                               0.995960   \n",
       "12586                   0.809524                               0.993197   \n",
       "2870                    0.757553                               0.966922   \n",
       "1767                    0.747733                               0.968667   \n",
       "1005                    0.873869                               0.980603   \n",
       "7665                    0.222039                               0.960882   \n",
       "1136                    0.720703                               0.983746   \n",
       "6046                    0.761959                               0.982297   \n",
       "799                     0.870968                               0.956989   \n",
       "3552                    0.760451                               0.968530   \n",
       "2577                    0.832609                               0.966105   \n",
       "10578                   0.953342                               0.988774   \n",
       "4641                    0.757806                               0.974749   \n",
       "9195                    0.476816                               0.996612   \n",
       "9007                    0.621876                               0.917017   \n",
       "356                     0.882502                               0.980417   \n",
       "2926                    0.842308                               0.930769   \n",
       "3696                    0.749814                               0.983331   \n",
       "8103                    0.900000                               0.937500   \n",
       "5947                    0.744577                               0.974947   \n",
       "6319                    0.739699                               0.977965   \n",
       "4351                    0.863014                               1.000000   \n",
       "2156                    0.794591                               0.967306   \n",
       "11540                   0.628280                               0.997813   \n",
       "674                     0.888889                               0.976190   \n",
       "4908                    0.536547                               0.537714   \n",
       "386                     0.580993                               0.920409   \n",
       "1571                    0.633828                               0.964234   \n",
       "11509                   0.928571                               0.996566   \n",
       "1216                    0.893604                               0.975971   \n",
       "4404                    0.752665                               0.969477   \n",
       "3849                    0.862608                               0.939605   \n",
       "13357                   0.817308                               0.996394   \n",
       "1390                    0.859935                               0.974369   \n",
       "10688                   0.778705                               0.996748   \n",
       "9886                    0.751531                               0.994751   \n",
       "10265                   0.863120                               0.958593   \n",
       "4586                    0.909276                               0.934760   \n",
       "328                     0.739597                               0.981030   \n",
       "137                     0.933538                               0.971370   \n",
       "6335                    0.843894                               0.976081   \n",
       "3801                    0.800542                               0.917073   \n",
       "\n",
       "       qstats_answered_correctly_knowing_having_had_explanation  \\\n",
       "8845                                            0.806523          \n",
       "9822                                            0.291742          \n",
       "9718                                            0.576562          \n",
       "7429                                            0.755551          \n",
       "6989                                            0.852368          \n",
       "6026                                            0.747922          \n",
       "1795                                            0.784349          \n",
       "3567                                            0.753545          \n",
       "2612                                            0.691209          \n",
       "1867                                            0.481693          \n",
       "12284                                           0.938931          \n",
       "12537                                           0.683962          \n",
       "9350                                            0.762975          \n",
       "6083                                            0.430696          \n",
       "5793                                            0.784399          \n",
       "10637                                           0.885106          \n",
       "10725                                           0.843836          \n",
       "12177                                           0.773333          \n",
       "12217                                           0.925625          \n",
       "12586                                           0.815068          \n",
       "2870                                            0.756377          \n",
       "1767                                            0.746456          \n",
       "1005                                            0.874347          \n",
       "7665                                            0.224388          \n",
       "1136                                            0.722217          \n",
       "6046                                            0.763390          \n",
       "799                                             0.887640          \n",
       "3552                                            0.760912          \n",
       "2577                                            0.833033          \n",
       "10578                                           0.952989          \n",
       "4641                                            0.762117          \n",
       "9195                                            0.477162          \n",
       "9007                                            0.637593          \n",
       "356                                             0.882598          \n",
       "2926                                            0.842975          \n",
       "3696                                            0.750719          \n",
       "8103                                            0.893333          \n",
       "5947                                            0.749922          \n",
       "6319                                            0.739146          \n",
       "4351                                            0.863014          \n",
       "2156                                            0.795081          \n",
       "11540                                           0.628196          \n",
       "674                                             0.886179          \n",
       "4908                                            0.599422          \n",
       "386                                             0.596066          \n",
       "1571                                            0.632454          \n",
       "11509                                           0.928325          \n",
       "1216                                            0.895884          \n",
       "4404                                            0.752874          \n",
       "3849                                            0.869910          \n",
       "13357                                           0.816647          \n",
       "1390                                            0.861565          \n",
       "10688                                           0.778868          \n",
       "9886                                            0.751979          \n",
       "10265                                           0.859669          \n",
       "4586                                            0.907306          \n",
       "328                                             0.742204          \n",
       "137                                             0.934737          \n",
       "6335                                            0.844153          \n",
       "3801                                            0.809693          \n",
       "\n",
       "       qstats_answered_correctly_knowing_having_not_had_explanation  \n",
       "8845                                            0.806452             \n",
       "9822                                            0.241935             \n",
       "9718                                            0.400000             \n",
       "7429                                            0.759615             \n",
       "6989                                            0.892116             \n",
       "6026                                            0.557895             \n",
       "1795                                            0.772727             \n",
       "3567                                            0.534483             \n",
       "2612                                            0.757225             \n",
       "1867                                            0.507973             \n",
       "12284                                           1.000000             \n",
       "12537                                           0.857143             \n",
       "9350                                            0.521429             \n",
       "6083                                            0.332117             \n",
       "5793                                            0.709898             \n",
       "10637                                           0.851852             \n",
       "10725                                           0.839506             \n",
       "12177                                           0.888889             \n",
       "12217                                           1.000000             \n",
       "12586                                           0.000000             \n",
       "2870                                            0.791908             \n",
       "1767                                            0.787234             \n",
       "1005                                            0.849741             \n",
       "7665                                            0.164319             \n",
       "1136                                            0.629032             \n",
       "6046                                            0.682584             \n",
       "799                                             0.500000             \n",
       "3552                                            0.746269             \n",
       "2577                                            0.820513             \n",
       "10578                                           0.984375             \n",
       "4641                                            0.591398             \n",
       "9195                                            0.375000             \n",
       "9007                                            0.448193             \n",
       "356                                             0.877698             \n",
       "2926                                            0.833333             \n",
       "3696                                            0.696429             \n",
       "8103                                            1.000000             \n",
       "5947                                            0.536585             \n",
       "6319                                            0.764228             \n",
       "4351                                            0.863014             \n",
       "2156                                            0.780105             \n",
       "11540                                           0.666667             \n",
       "674                                             1.000000             \n",
       "4908                                            0.463415             \n",
       "386                                             0.406675             \n",
       "1571                                            0.670886             \n",
       "11509                                           1.000000             \n",
       "1216                                            0.800995             \n",
       "4404                                            0.746032             \n",
       "3849                                            0.749004             \n",
       "13357                                           1.000000             \n",
       "1390                                            0.797980             \n",
       "10688                                           0.728814             \n",
       "9886                                            0.666667             \n",
       "10265                                           0.943005             \n",
       "4586                                            0.937500             \n",
       "328                                             0.604743             \n",
       "137                                             0.892857             \n",
       "6335                                            0.833333             \n",
       "3801                                            0.699346             "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sample_100.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:22:26.466154Z",
     "start_time": "2020-12-16T14:22:26.447580Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def initialize_user():\n",
    "    user_correct_answers_cum_parts=[6/random.random() for _ in range(7)]\n",
    "    user_avg_score_cum_parts=[random.random() for _ in range(7)]\n",
    "    user_correct_answers_cum = sum(user_correct_answers_cum_parts)\n",
    "    user_avg_score_cum=user_correct_answers_cum\\\n",
    "                       /sum([user_correct_answers_cum_parts[i]/user_avg_score_cum_parts[i] for i in range(7)])\n",
    "    at_least_one_lecture=random.randint(0,1)\n",
    "    lectures=at_least_one_lecture*random.randint(1,10)\n",
    "    activity_count=lectures+user_correct_answers_cum/user_avg_score_cum\n",
    "    \n",
    "    user_history=pd.DataFrame({\n",
    "                             #following columns are the impute of each loop\n",
    "                             ### TO BE IMPUTED ###\n",
    "                             'content_id':[-1],\n",
    "                             'content_type_id':[-1],\n",
    "                             'prior_question_had_explanation':False,\n",
    "                             'mode':'n/a',\n",
    "                             # following columns depend of previous history of the user : \n",
    "                             ### TO BE UPDATED WHATEVER THE CONTENT_TYPE ###\n",
    "                             'user_activity_cumcount':[activity_count],\n",
    "                             ### TO BE UPDATED IF LAST WAS LECTURE ###\n",
    "                             'at_least_one_lesson':[at_least_one_lecture],\n",
    "                             ### TO BE UPDATED IF LAST WAS QUESTION ###\n",
    "                             'user_avg_score_cum':[user_avg_score_cum],\n",
    "                             'user_correct_answers_cum':[user_correct_answers_cum],\n",
    "                             'user_avg_score_cum_part1':[user_correct_answers_cum_parts[0]],\n",
    "                             'user_avg_score_cum_part2':[user_correct_answers_cum_parts[1]],\n",
    "                             'user_avg_score_cum_part3':[user_correct_answers_cum_parts[2]],\n",
    "                             'user_avg_score_cum_part4':[user_correct_answers_cum_parts[3]],\n",
    "                             'user_avg_score_cum_part5':[user_correct_answers_cum_parts[4]],\n",
    "                             'user_avg_score_cum_part6':[user_correct_answers_cum_parts[5]],\n",
    "                             'user_avg_score_cum_part7':[user_correct_answers_cum_parts[6]],\n",
    "                             'user_correct_answers_cum_part1':[user_avg_score_cum_parts[0]],\n",
    "                             'user_correct_answers_cum_part2':[user_avg_score_cum_parts[1]],\n",
    "                             'user_correct_answers_cum_part3':[user_avg_score_cum_parts[2]],\n",
    "                             'user_correct_answers_cum_part4':[user_avg_score_cum_parts[3]],\n",
    "                             'user_correct_answers_cum_part5':[user_avg_score_cum_parts[4]],\n",
    "                             'user_correct_answers_cum_part6':[user_avg_score_cum_parts[5]],\n",
    "                             'user_correct_answers_cum_part7':[user_avg_score_cum_parts[6]],\n",
    "                             # following columns are pure question stats : \n",
    "                             ### TO BE IMPORTED FROM QUESTIONS ###\n",
    "                             'part':[-1],\n",
    "                             'qstats_answered_correctly':[-1],\n",
    "                             'qstats_prior_question_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_not_had_explanation':[-1],\n",
    "                             # following columns depend of the current question AND the hisory of user\n",
    "                             ### TO BE COMPUTED ###\n",
    "                             'user_personalized_qstat_knowing_had_explanation_or_not':[-1],\n",
    "                             'already_seen':[-1],\n",
    "                             'user_avg_score_cum_on_this_part':[-1],\n",
    "                             'user_correct_answers_cum_on_this_part':[-1],\n",
    "                             # the following line is the prediction to be made\n",
    "                             ### TO BE PREDICTED ###\n",
    "                             'answered_correctly':[-1]\n",
    "                          })\n",
    "    return user_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:22:28.393331Z",
     "start_time": "2020-12-16T14:22:28.341290Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>mode</th>\n",
       "      <th>user_activity_cumcount</th>\n",
       "      <th>at_least_one_lesson</th>\n",
       "      <th>user_avg_score_cum</th>\n",
       "      <th>user_correct_answers_cum</th>\n",
       "      <th>user_avg_score_cum_part1</th>\n",
       "      <th>user_avg_score_cum_part2</th>\n",
       "      <th>...</th>\n",
       "      <th>part</th>\n",
       "      <th>qstats_answered_correctly</th>\n",
       "      <th>qstats_prior_question_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_not_had_explanation</th>\n",
       "      <th>user_personalized_qstat_knowing_had_explanation_or_not</th>\n",
       "      <th>already_seen</th>\n",
       "      <th>user_avg_score_cum_on_this_part</th>\n",
       "      <th>user_correct_answers_cum_on_this_part</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>n/a</td>\n",
       "      <td>176.476254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617626</td>\n",
       "      <td>104.055333</td>\n",
       "      <td>12.770518</td>\n",
       "      <td>35.307275</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  content_type_id  prior_question_had_explanation mode  \\\n",
       "0          -1               -1                           False  n/a   \n",
       "\n",
       "   user_activity_cumcount  at_least_one_lesson  user_avg_score_cum  \\\n",
       "0              176.476254                    1            0.617626   \n",
       "\n",
       "   user_correct_answers_cum  user_avg_score_cum_part1  \\\n",
       "0                104.055333                 12.770518   \n",
       "\n",
       "   user_avg_score_cum_part2  ...  part  qstats_answered_correctly  \\\n",
       "0                 35.307275  ...    -1                         -1   \n",
       "\n",
       "   qstats_prior_question_had_explanation  \\\n",
       "0                                     -1   \n",
       "\n",
       "   qstats_answered_correctly_knowing_having_had_explanation  \\\n",
       "0                                                 -1          \n",
       "\n",
       "   qstats_answered_correctly_knowing_having_not_had_explanation  \\\n",
       "0                                                 -1              \n",
       "\n",
       "   user_personalized_qstat_knowing_had_explanation_or_not  already_seen  \\\n",
       "0                                                 -1                 -1   \n",
       "\n",
       "   user_avg_score_cum_on_this_part  user_correct_answers_cum_on_this_part  \\\n",
       "0                               -1                                     -1   \n",
       "\n",
       "   answered_correctly  \n",
       "0                  -1  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:29:51.077348Z",
     "start_time": "2020-12-16T14:29:51.068215Z"
    }
   },
   "outputs": [],
   "source": [
    "#from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Configuration paramaters for the whole setup\n",
    "#seed = 42\n",
    "gamma = 0.99  # Discount factor for past rewards\n",
    "epsilon = 1.0  # Epsilon greedy parameter\n",
    "epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
    "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
    "epsilon_interval = (\n",
    "    epsilon_max - epsilon_min\n",
    ")  # Rate at which to reduce chance of random action being taken\n",
    "batch_size = 32  # Size of batch taken from replay buffer\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "# Use the Baseline Atari environment because of Deepmind helper functions\n",
    "env = initialize_user\n",
    "# Warp the frames, grey scale, stake four frame and scale to smaller ratio\n",
    "#env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "#env.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:23:30.090338Z",
     "start_time": "2020-12-16T14:23:29.910814Z"
    }
   },
   "outputs": [],
   "source": [
    "num_actions = 1000\n",
    "\n",
    "def create_q_model():\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=(84, 84, 4,))\n",
    "\n",
    "    # Convolutions on the frames on the screen\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "\n",
    "# The first model makes the predictions for Q-values which are used to\n",
    "# make a action.\n",
    "model = create_q_model()\n",
    "# Build a target model for the prediction of future rewards.\n",
    "# The weights of a target model get updated every 10000 steps thus when the\n",
    "# loss between the Q-values is calculated the target Q-value is stable.\n",
    "model_target = create_q_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T15:47:35.320787Z",
     "start_time": "2020-12-16T15:45:28.265054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7027287949623343\n",
      "0.6042227523615585\n",
      "0.3521048026512498\n",
      "0.6070345221085962\n",
      "0.7027287949623343\n",
      "0.6070345221085962\n",
      "0.3521048026512498\n",
      "0.3521048026512498\n",
      "0.5805195413440043\n",
      "0.5805195413440043\n",
      "0.7027287949623343\n",
      "0.5805195413440043\n",
      "0.6070345221085962\n",
      "0.18006865828923327\n",
      "0.6070345221085962\n",
      "0.3521048026512498\n",
      "0.7027287949623343\n",
      "0.7027287949623343\n",
      "0.3521048026512498\n",
      "0.18006865828923327\n",
      "0.5805195413440043\n",
      "0.7027287949623343\n",
      "0.3521048026512498\n",
      "0.6070345221085962\n",
      "0.7266372890462325\n",
      "0.6070345221085962\n",
      "0.6070345221085962\n",
      "0.5805195413440043\n",
      "0.3521048026512498\n",
      "0.18006865828923327\n",
      "0.18006865828923327\n",
      "0.5805195413440043\n",
      "0.5805195413440043\n",
      "0.18006865828923327\n",
      "0.6070345221085962\n",
      "0.5805195413440043\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-7794b91fa756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# Build the updated Q-values for the sampled future states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# Use the target model for stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mfuture_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_next_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0;31m# Q value = reward + discount factor * expected future reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             updated_q_values = rewards_sample + gamma * tf.reduce_max(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m                **kwargs):\n\u001b[1;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "# In the Deepmind paper they use RMSProp however then Adam optimizer\n",
    "# improves training time\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "\n",
    "# Experience replay buffers\n",
    "action_history = []\n",
    "state_history = []\n",
    "state_next_history = []\n",
    "rewards_history = []\n",
    "done_history = []\n",
    "episode_reward_history = []\n",
    "running_reward = 0\n",
    "episode_count = 0\n",
    "frame_count = 0\n",
    "# Number of frames to take random action and observe output\n",
    "epsilon_random_frames = 50000\n",
    "# Number of frames for exploration\n",
    "epsilon_greedy_frames = 1000000.0\n",
    "# Maximum replay length\n",
    "# Note: The Deepmind paper suggests 1000000 however this causes memory issues\n",
    "max_memory_length = 100000\n",
    "# Train the model after 4 actions\n",
    "update_after_actions = 4\n",
    "# How often to update the target network\n",
    "update_target_network = 10000\n",
    "# Using huber loss for stability\n",
    "loss_function = keras.losses.Huber()\n",
    "\n",
    "while True:  # Run until solved\n",
    "    state_df=env()\n",
    "    state = np.array(state_df)\n",
    "    episode_reward = 0\n",
    "\n",
    "    for timestep in range(1, max_steps_per_episode):\n",
    "        # env.render(); Adding this line would show the attempts\n",
    "        # of the agent in a pop up window.\n",
    "        frame_count += 1\n",
    "\n",
    "        # Use epsilon-greedy for exploration\n",
    "        if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
    "            # Take random action\n",
    "            action = np.random.choice(num_actions)\n",
    "        else:\n",
    "            # Predict action Q-values\n",
    "            # From environment state\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = model(state_tensor, training=False)\n",
    "            # Take best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()\n",
    "\n",
    "        # Decay probability of taking random action\n",
    "        epsilon -= epsilon_interval / epsilon_greedy_frames\n",
    "        epsilon = max(epsilon, epsilon_min)\n",
    "\n",
    "        # Apply the sampled action in our environment\n",
    "        \n",
    "        question_id=q_sample_100.iloc[action].content_id\n",
    "        state_next = user_history_update(0,\n",
    "                                         question_id,\n",
    "                                         q_sample_100,\n",
    "                                         state_df,\n",
    "                                         mode='training',\n",
    "                                         prior_question_had_explanation=random.uniform(0, 1)>0.1).iloc[[-1]]\n",
    "        \n",
    "        print(my_pipeline.predict_proba(state_next[pipeline_features_list.feature.to_list()])[0][-1])\n",
    "        \n",
    "        state_next.iloc[-1,-1]\\\n",
    "                = my_pipeline.predict_proba(state_next[pipeline_features_list.feature.to_list()])[0][-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        reward = TOEIC_scoring (qstats,\n",
    "                                state_df,\n",
    "                                number_of_questions=100,\n",
    "                                TOEIC_strategy='random')\n",
    "        done = False\n",
    "        \n",
    "        state_next = np.array(state_next)\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Save actions and states in replay buffer\n",
    "        action_history.append(action)\n",
    "        state_history.append(state)\n",
    "        state_next_history.append(state_next)\n",
    "        done_history.append(done)\n",
    "        rewards_history.append(reward)\n",
    "        state = state_next\n",
    "\n",
    "        # Update every fourth frame and once batch size is over 32\n",
    "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
    "\n",
    "            # Get indices of samples for replay buffers\n",
    "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "\n",
    "            # Using list comprehension to sample from replay buffer\n",
    "            state_sample = np.array([state_history[i] for i in indices])\n",
    "            state_next_sample = np.array([state_next_history[i] for i in indices])\n",
    "            rewards_sample = [rewards_history[i] for i in indices]\n",
    "            action_sample = [action_history[i] for i in indices]\n",
    "            done_sample = tf.convert_to_tensor(\n",
    "                [float(done_history[i]) for i in indices]\n",
    "            )\n",
    "\n",
    "            # Build the updated Q-values for the sampled future states\n",
    "            # Use the target model for stability\n",
    "            future_rewards = model_target.predict(state_next_sample)\n",
    "            # Q value = reward + discount factor * expected future reward\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(\n",
    "                future_rewards, axis=1\n",
    "            )\n",
    "\n",
    "            # If final frame set the last value to -1\n",
    "            updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
    "\n",
    "            # Create a mask so we only calculate loss on the updated Q-values\n",
    "            masks = tf.one_hot(action_sample, num_actions)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Train the model on the states and updated Q-values\n",
    "                q_values = model(state_sample)\n",
    "\n",
    "                # Apply the masks to the Q-values to get the Q-value for action taken\n",
    "                q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                # Calculate loss between new Q-value and old Q-value\n",
    "                loss = loss_function(updated_q_values, q_action)\n",
    "\n",
    "            # Backpropagation\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if frame_count % update_target_network == 0:\n",
    "            # update the the target network with new weights\n",
    "            model_target.set_weights(model.get_weights())\n",
    "            # Log details\n",
    "            template = \"running reward: {:.2f} at episode {}, frame count {}\"\n",
    "            print(template.format(running_reward, episode_count, frame_count))\n",
    "\n",
    "        # Limit the state and reward history\n",
    "        if len(rewards_history) > max_memory_length:\n",
    "            del rewards_history[:1]\n",
    "            del state_history[:1]\n",
    "            del state_next_history[:1]\n",
    "            del action_history[:1]\n",
    "            del done_history[:1]\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update running reward to check condition for solving\n",
    "    episode_reward_history.append(episode_reward)\n",
    "    if len(episode_reward_history) > 100:\n",
    "        del episode_reward_history[:1]\n",
    "    running_reward = np.mean(episode_reward_history)\n",
    "\n",
    "    episode_count += 1\n",
    "    print(f'finished episode {episode_count}')\n",
    "\n",
    "    if running_reward > 40:  # Condition to consider the task solved\n",
    "        print(\"Solved at episode {}!\".format(episode_count))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:05:11.763090Z",
     "start_time": "2020-12-16T14:05:11.754317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.8605973370782"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:14:01.086529Z",
     "start_time": "2020-12-16T14:14:01.070293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.2607951101677"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([10/random.random() for _ in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:14:19.140410Z",
     "start_time": "2020-12-16T14:14:19.135265Z"
    }
   },
   "outputs": [],
   "source": [
    "a=[10/random.random() for _ in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:14:36.104434Z",
     "start_time": "2020-12-16T14:14:36.092598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b/b for b in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:16:45.912041Z",
     "start_time": "2020-12-16T14:16:45.903994Z"
    }
   },
   "outputs": [],
   "source": [
    "user_correct_answers_cum_parts=[6/random.random() for _ in range(7)]\n",
    "user_avg_score_cum_parts=[random.random() for _ in range(7)]\n",
    "user_correct_answers_cum = sum(user_correct_answers_cum_parts)\n",
    "user_avg_score_cum=user_correct_answers_cum\\\n",
    "                       /sum([user_correct_answers_cum_parts[i]/user_avg_score_cum_parts[i] for i in range(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:16:50.685256Z",
     "start_time": "2020-12-16T14:16:50.676539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31164429509095226"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_avg_score_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:16:55.191911Z",
     "start_time": "2020-12-16T14:16:55.183830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2945215822635604,\n",
       " 0.817543944263933,\n",
       " 0.1283249480800267,\n",
       " 0.3337338763658291,\n",
       " 0.28626992397225115,\n",
       " 0.3500381226979695,\n",
       " 0.3536403240885838]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_avg_score_cum_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:17:03.495035Z",
     "start_time": "2020-12-16T14:17:03.484700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.251570307168933,\n",
       " 8.287184819144526,\n",
       " 12.803938751299356,\n",
       " 51.83405437545735,\n",
       " 18.255677774745003,\n",
       " 96.90053311736297,\n",
       " 11.586324261763494]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_correct_answers_cum_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
