{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:16.751745Z",
     "start_time": "2020-12-15T16:00:15.821986Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import q_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:16.828566Z",
     "start_time": "2020-12-15T16:00:16.757150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>qstats_count</th>\n",
       "      <th>qstats_answered_correctly</th>\n",
       "      <th>qstats_prior_question_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_not_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51 131 162 38</td>\n",
       "      <td>6903</td>\n",
       "      <td>0.907721</td>\n",
       "      <td>0.948138</td>\n",
       "      <td>0.911994</td>\n",
       "      <td>0.829609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "      <td>7398</td>\n",
       "      <td>0.890646</td>\n",
       "      <td>0.980400</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.813793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 101 162 92</td>\n",
       "      <td>44905</td>\n",
       "      <td>0.554281</td>\n",
       "      <td>0.888253</td>\n",
       "      <td>0.562213</td>\n",
       "      <td>0.491232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 149 162 29</td>\n",
       "      <td>22973</td>\n",
       "      <td>0.779437</td>\n",
       "      <td>0.958473</td>\n",
       "      <td>0.783460</td>\n",
       "      <td>0.686583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>131 5 162 38</td>\n",
       "      <td>31736</td>\n",
       "      <td>0.613215</td>\n",
       "      <td>0.530313</td>\n",
       "      <td>0.654308</td>\n",
       "      <td>0.566819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13518</th>\n",
       "      <td>13518</td>\n",
       "      <td>13518</td>\n",
       "      <td>13518</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>868</td>\n",
       "      <td>0.786866</td>\n",
       "      <td>0.998848</td>\n",
       "      <td>0.786621</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>13519</td>\n",
       "      <td>13519</td>\n",
       "      <td>13519</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>924</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.994589</td>\n",
       "      <td>0.570185</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>13520</td>\n",
       "      <td>13520</td>\n",
       "      <td>13520</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>861</td>\n",
       "      <td>0.672474</td>\n",
       "      <td>0.995354</td>\n",
       "      <td>0.670945</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>13521</td>\n",
       "      <td>13521</td>\n",
       "      <td>13521</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>870</td>\n",
       "      <td>0.808046</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.808535</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>13522</td>\n",
       "      <td>13522</td>\n",
       "      <td>13522</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>860</td>\n",
       "      <td>0.913953</td>\n",
       "      <td>0.991860</td>\n",
       "      <td>0.913247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13523 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  content_id  bundle_id  correct_answer  part  \\\n",
       "0               0           0          0               0     1   \n",
       "1               1           1          1               1     1   \n",
       "2               2           2          2               0     1   \n",
       "3               3           3          3               0     1   \n",
       "4               4           4          4               3     1   \n",
       "...           ...         ...        ...             ...   ...   \n",
       "13518       13518       13518      13518               3     5   \n",
       "13519       13519       13519      13519               3     5   \n",
       "13520       13520       13520      13520               2     5   \n",
       "13521       13521       13521      13521               0     5   \n",
       "13522       13522       13522      13522               3     5   \n",
       "\n",
       "                 tags  qstats_count  qstats_answered_correctly  \\\n",
       "0       51 131 162 38          6903                   0.907721   \n",
       "1           131 36 81          7398                   0.890646   \n",
       "2      131 101 162 92         44905                   0.554281   \n",
       "3      131 149 162 29         22973                   0.779437   \n",
       "4        131 5 162 38         31736                   0.613215   \n",
       "...               ...           ...                        ...   \n",
       "13518              14           868                   0.786866   \n",
       "13519               8           924                   0.571429   \n",
       "13520              73           861                   0.672474   \n",
       "13521             125           870                   0.808046   \n",
       "13522              55           860                   0.913953   \n",
       "\n",
       "       qstats_prior_question_had_explanation  \\\n",
       "0                                   0.948138   \n",
       "1                                   0.980400   \n",
       "2                                   0.888253   \n",
       "3                                   0.958473   \n",
       "4                                   0.530313   \n",
       "...                                      ...   \n",
       "13518                               0.998848   \n",
       "13519                               0.994589   \n",
       "13520                               0.995354   \n",
       "13521                               0.996552   \n",
       "13522                               0.991860   \n",
       "\n",
       "       qstats_answered_correctly_knowing_having_had_explanation  \\\n",
       "0                                               0.911994          \n",
       "1                                               0.892183          \n",
       "2                                               0.562213          \n",
       "3                                               0.783460          \n",
       "4                                               0.654308          \n",
       "...                                                  ...          \n",
       "13518                                           0.786621          \n",
       "13519                                           0.570185          \n",
       "13520                                           0.670945          \n",
       "13521                                           0.808535          \n",
       "13522                                           0.913247          \n",
       "\n",
       "       qstats_answered_correctly_knowing_having_not_had_explanation  \n",
       "0                                               0.829609             \n",
       "1                                               0.813793             \n",
       "2                                               0.491232             \n",
       "3                                               0.686583             \n",
       "4                                               0.566819             \n",
       "...                                                  ...             \n",
       "13518                                           1.000000             \n",
       "13519                                           0.800000             \n",
       "13520                                           1.000000             \n",
       "13521                                           0.666667             \n",
       "13522                                           1.000000             \n",
       "\n",
       "[13523 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qstats=pd.read_csv('../data/qstats_for_M1')\n",
    "qstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:18.945233Z",
     "start_time": "2020-12-15T16:00:16.841500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasmathieu/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/thomasmathieu/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.20.4 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/thomasmathieu/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.gradient_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'BinomialDeviance' on <module 'sklearn.ensemble.gradient_boosting' from '/Users/thomasmathieu/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f3dcd0dcd970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/xgboost_pipe_M1.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## wb= write bites : le b est important\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'BinomialDeviance' on <module 'sklearn.ensemble.gradient_boosting' from '/Users/thomasmathieu/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py'>"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "my_pipeline = pickle.load(open('../models/xgboost_pipe_M1.pkl',\"rb\"))  ## wb= write bites : le b est important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:18.951235Z",
     "start_time": "2020-12-15T16:00:15.829Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_features_list=pd.read_csv('../models/xgboost_pipe_M1_features_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:18.955863Z",
     "start_time": "2020-12-15T16:00:15.833Z"
    }
   },
   "outputs": [],
   "source": [
    "[pipeline_features_list.feature.to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation utilisateur débutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:18.960333Z",
     "start_time": "2020-12-15T16:00:15.837Z"
    }
   },
   "outputs": [],
   "source": [
    "user_history_empty=pd.DataFrame({#following columns are the impute of each loop\n",
    "                             ### TO BE IMPUTED ###\n",
    "                             'content_id':[-1],\n",
    "                             'content_type_id':[-1],\n",
    "                             'prior_question_had_explanation':False,\n",
    "                             # following columns depend of previous history of the user : \n",
    "                             ### TO BE UPDATED WHATEVER THE CONTENT_TYPE ###\n",
    "                             'user_activity_cumcount':[-1],\n",
    "                             'at_least_one_lesson':[0],\n",
    "                             ### TO BE UPDATED IF LAST WAS QUESTION , ELSE COPIED ###\n",
    "                             'user_avg_score_cum':[0.499],\n",
    "                             'user_correct_answers_cum':[0],\n",
    "                             'user_avg_score_cum_part1':[0.499],\n",
    "                             'user_avg_score_cum_part2':[0.499],\n",
    "                             'user_avg_score_cum_part3':[0.499],\n",
    "                             'user_avg_score_cum_part4':[0.499],\n",
    "                             'user_avg_score_cum_part5':[0.499],\n",
    "                             'user_avg_score_cum_part6':[0.499],\n",
    "                             'user_avg_score_cum_part7':[0.499],\n",
    "                             'user_correct_answers_cum_part1':[0],\n",
    "                             'user_correct_answers_cum_part2':[0],\n",
    "                             'user_correct_answers_cum_part3':[0],\n",
    "                             'user_correct_answers_cum_part4':[0],\n",
    "                             'user_correct_answers_cum_part5':[0],\n",
    "                             'user_correct_answers_cum_part6':[0],\n",
    "                             'user_correct_answers_cum_part7':[0],\n",
    "                             # following columns are pure question stats : \n",
    "                             ### TO BE IMPORTED ###\n",
    "                             'part':[-1],\n",
    "                             'qstats_answered_correctly':[-1],\n",
    "                             'qstats_prior_question_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_not_had_explanation':[-1],\n",
    "                             # following columns depend of the current question AND the hisory of user\n",
    "                             ### TO BE COMPUTED ###\n",
    "                             'user_personalized_qstat_knowing_had_explanation_or_not':[-1],\n",
    "                             'already_seen':[-1],\n",
    "                             'user_avg_score_cum_on_this_part':[-1],\n",
    "                             'user_correct_answers_cum_on_this_part':[-1],\n",
    "                             # the following line is the prediction to be made\n",
    "                             ### TO BE PREDICTED ###\n",
    "                             'answered_correctly':[-1]\n",
    "                          })\n",
    "user_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User history update fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:52.861240Z",
     "start_time": "2020-12-15T16:00:52.825933Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_history_update(content_type_id,\n",
    "                        content_id,\n",
    "                        data_qstats,\n",
    "                        user_history=None,\n",
    "                        prior_question_had_explanation=False):\n",
    "    '''Crée ou met à jour l'hisorique d'un utilisateur, stockée dans un df'''\n",
    "    \n",
    "    user_history_empty=pd.DataFrame({\n",
    "                             #following columns are the impute of each loop\n",
    "                             ### TO BE IMPUTED ###\n",
    "                             'content_id':[-1],\n",
    "                             'content_type_id':[-1],\n",
    "                             'prior_question_had_explanation':False,\n",
    "                             # following columns depend of previous history of the user : \n",
    "                             ### TO BE UPDATED WHATEVER THE CONTENT_TYPE ###\n",
    "                             'user_activity_cumcount':[-1],\n",
    "                             'at_least_one_lesson':[0],\n",
    "                             ### TO BE UPDATED IF LAST WAS QUESTION , ELSE COPIED ###\n",
    "                             'user_avg_score_cum':[0.499],\n",
    "                             'user_correct_answers_cum':[0],\n",
    "                             'user_avg_score_cum_part1':[0.499],\n",
    "                             'user_avg_score_cum_part2':[0.499],\n",
    "                             'user_avg_score_cum_part3':[0.499],\n",
    "                             'user_avg_score_cum_part4':[0.499],\n",
    "                             'user_avg_score_cum_part5':[0.499],\n",
    "                             'user_avg_score_cum_part6':[0.499],\n",
    "                             'user_avg_score_cum_part7':[0.499],\n",
    "                             'user_correct_answers_cum_part1':[0],\n",
    "                             'user_correct_answers_cum_part2':[0],\n",
    "                             'user_correct_answers_cum_part3':[0],\n",
    "                             'user_correct_answers_cum_part4':[0],\n",
    "                             'user_correct_answers_cum_part5':[0],\n",
    "                             'user_correct_answers_cum_part6':[0],\n",
    "                             'user_correct_answers_cum_part7':[0],\n",
    "                             # following columns are pure question stats : \n",
    "                             ### TO BE IMPORTED ###\n",
    "                             'part':[-1],\n",
    "                             'qstats_answered_correctly':[-1],\n",
    "                             'qstats_prior_question_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_had_explanation':[-1],\n",
    "                             'qstats_answered_correctly_knowing_having_not_had_explanation':[-1],\n",
    "                             # following columns depend of the current question AND the hisory of user\n",
    "                             ### TO BE COMPUTED ###\n",
    "                             'user_personalized_qstat_knowing_had_explanation_or_not':[-1],\n",
    "                             'already_seen':[-1],\n",
    "                             'user_avg_score_cum_on_this_part':[-1],\n",
    "                             'user_correct_answers_cum_on_this_part':[-1],\n",
    "                             # the following line is the prediction to be made\n",
    "                             ### TO BE PREDICTED ###\n",
    "                             'answered_correctly':[-1]\n",
    "                          })\n",
    "    \n",
    "    if not type(user_history)==pd.DataFrame:\n",
    "        user_history=user_history_empty\n",
    "    \n",
    "    last_line=user_history.iloc[-1]\n",
    "    new_line =last_line.copy()\n",
    "    \n",
    "    last_content_type_id=user_history.iloc[-1]['content_type_id']\n",
    "    \n",
    "    ### TO BE IMPUTED ###\n",
    "    new_line['content_id']=content_id\n",
    "    new_line['content_type_id']=content_type_id\n",
    "    new_line['prior_question_had_explanation']=prior_question_had_explanation\n",
    "    ### TO BE UPDATED WHATEVER THE CONTENT_TYPE ###\n",
    "    new_line['user_activity_cumcount'] = last_line['user_activity_cumcount'] + 1\n",
    "    new_line['at_least_one_lesson'] = last_line['at_least_one_lesson']\n",
    "\n",
    "    if last_content_type_id==0:\n",
    "        part=last_line['part']\n",
    "        ### TO BE UPDATED IF LAST WAS QUESTION , ELSE COPIED ###\n",
    "        new_line['user_correct_answers_cum'] = last_line['user_correct_answers_cum']\\\n",
    "                                             + last_line['answered_correctly']\n",
    "        new_user_questions_count             = last_line['user_correct_answers_cum']\\\n",
    "                                             / last_line['user_avg_score_cum']\\\n",
    "                                             + 1\n",
    "        new_line['user_avg_score_cum']       = new_line['user_correct_answers_cum']\\\n",
    "                                             / new_user_questions_count\n",
    "\n",
    "        new_line[f'user_correct_answers_cum_part{part}'] = last_line[f'user_correct_answers_cum_part{part}']\\\n",
    "                                                         + last_line['answered_correctly']\n",
    "        vars()[f'new_user_questions_count_part{part}']   = last_line[f'user_correct_answers_cum_part{part}']\\\n",
    "                                                         / last_line[f'user_avg_score_cum_part{part}']\\\n",
    "                                                         + 1\n",
    "        new_line[f'user_avg_score_cum_part{part}']       = new_line[f'user_correct_answers_cum_part{part}']\\\n",
    "                                                         / vars()[f'new_user_questions_count_part{part}']                \n",
    "        \n",
    "    if content_type_id==0:        \n",
    "        currect_question_stats=qstats.loc[qstats.content_id==content_id].iloc[-1]\n",
    "        ### TO BE IMPORTED ###\n",
    "        new_line['part']\\\n",
    "              = currect_question_stats['part']\n",
    "        new_line['qstats_answered_correctly']\\\n",
    "              = currect_question_stats['qstats_answered_correctly']\n",
    "        new_line['qstats_prior_question_had_explanation']\\\n",
    "              = currect_question_stats['qstats_prior_question_had_explanation']\n",
    "        new_line['qstats_answered_correctly_knowing_having_had_explanation']\\\n",
    "              = currect_question_stats['qstats_answered_correctly_knowing_having_had_explanation']\n",
    "        new_line['qstats_answered_correctly_knowing_having_not_had_explanation']\\\n",
    "              = currect_question_stats['qstats_answered_correctly_knowing_having_not_had_explanation']\n",
    "        ### TO BE COMPUTED ###\n",
    "        new_line['user_personalized_qstat_knowing_had_explanation_or_not']\\\n",
    "              = new_line['qstats_answered_correctly_knowing_having_had_explanation']\\\n",
    "             if prior_question_had_explanation\\\n",
    "           else new_line['qstats_answered_correctly_knowing_having_not_had_explanation']\n",
    "        new_line['already_seen']\\\n",
    "              = 1 if content_id in user_history.loc[user_history.content_type_id==0,'content_id']\\\n",
    "           else 0\n",
    "        new_line['user_avg_score_cum_on_this_part']=new_line[f'user_avg_score_cum_part{new_line[\"part\"]}']\n",
    "        new_line['user_correct_answers_cum_on_this_part']=new_line[f'user_correct_answers_cum_part{new_line[\"part\"]}']\n",
    "                                              \n",
    "    elif content_type_id==1:\n",
    "        ### TO BE UPDATED WHATEVER THE CONTENT_TYPE ###\n",
    "        new_line['at_least_one_lesson']=1\n",
    "        ### TO BE IMPORTED ###\n",
    "        new_line['part']= -1 # TODO : si on veut utiliser la partie de la lecture, il faut importer la base des lectures\n",
    "        new_line['qstats_answered_correctly']= -1\n",
    "        new_line['qstats_prior_question_had_explanation']= -1\n",
    "        new_line['qstats_answered_correctly_knowing_having_had_explanation']= -1\n",
    "        new_line['qstats_answered_correctly_knowing_having_not_had_explanation']= -1\n",
    "        ### TO BE COMPUTED ###\n",
    "        new_line['user_personalized_qstat_knowing_had_explanation_or_not']= -1\n",
    "        new_line['already_seen']= -1\n",
    "        new_line['user_avg_score_cum_on_this_part']= -1\n",
    "        new_line['user_correct_answers_cum_on_this_part']= -1\n",
    "        \n",
    "    ### TO BE PREDICTED ###\n",
    "    new_line['answered_correctly']= -1\n",
    "                                \n",
    "    user_history=user_history.append(new_line,ignore_index=True)\n",
    "\n",
    "    return user_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:57.982848Z",
     "start_time": "2020-12-15T16:00:57.897738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_activity_cumcount</th>\n",
       "      <th>at_least_one_lesson</th>\n",
       "      <th>user_avg_score_cum</th>\n",
       "      <th>user_correct_answers_cum</th>\n",
       "      <th>user_avg_score_cum_part1</th>\n",
       "      <th>user_avg_score_cum_part2</th>\n",
       "      <th>user_avg_score_cum_part3</th>\n",
       "      <th>...</th>\n",
       "      <th>part</th>\n",
       "      <th>qstats_answered_correctly</th>\n",
       "      <th>qstats_prior_question_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_not_had_explanation</th>\n",
       "      <th>user_personalized_qstat_knowing_had_explanation_or_not</th>\n",
       "      <th>already_seen</th>\n",
       "      <th>user_avg_score_cum_on_this_part</th>\n",
       "      <th>user_correct_answers_cum_on_this_part</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13522</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.913953</td>\n",
       "      <td>0.99186</td>\n",
       "      <td>0.913247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  content_type_id  prior_question_had_explanation  \\\n",
       "0          -1               -1                           False   \n",
       "1       13522                0                           False   \n",
       "\n",
       "   user_activity_cumcount  at_least_one_lesson  user_avg_score_cum  \\\n",
       "0                      -1                    0               0.499   \n",
       "1                       0                    0               0.499   \n",
       "\n",
       "   user_correct_answers_cum  user_avg_score_cum_part1  \\\n",
       "0                         0                     0.499   \n",
       "1                         0                     0.499   \n",
       "\n",
       "   user_avg_score_cum_part2  user_avg_score_cum_part3  ...  part  \\\n",
       "0                     0.499                     0.499  ...    -1   \n",
       "1                     0.499                     0.499  ...     5   \n",
       "\n",
       "   qstats_answered_correctly  qstats_prior_question_had_explanation  \\\n",
       "0                  -1.000000                               -1.00000   \n",
       "1                   0.913953                                0.99186   \n",
       "\n",
       "   qstats_answered_correctly_knowing_having_had_explanation  \\\n",
       "0                                          -1.000000          \n",
       "1                                           0.913247          \n",
       "\n",
       "   qstats_answered_correctly_knowing_having_not_had_explanation  \\\n",
       "0                                               -1.0              \n",
       "1                                                1.0              \n",
       "\n",
       "   user_personalized_qstat_knowing_had_explanation_or_not  already_seen  \\\n",
       "0                                               -1.0                 -1   \n",
       "1                                                1.0                  0   \n",
       "\n",
       "   user_avg_score_cum_on_this_part  user_correct_answers_cum_on_this_part  \\\n",
       "0                           -1.000                                     -1   \n",
       "1                            0.499                                      0   \n",
       "\n",
       "   answered_correctly  \n",
       "0                -1.0  \n",
       "1                 0.8  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history=user_history_update(0, #content_type_id=0 <=> question\n",
    "                                 13522, #numéro d'une question au hasard\n",
    "                                 qstats, #df des stats questions\n",
    "                                 user_history=None, #None pour une utilisateur nouveau\n",
    "                                 prior_question_had_explanation=False, #\n",
    "                                )\n",
    "user_history.iloc[-1,-1]=0.8\n",
    "user_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:58.860823Z",
     "start_time": "2020-12-15T16:00:58.789479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>user_activity_cumcount</th>\n",
       "      <th>at_least_one_lesson</th>\n",
       "      <th>user_avg_score_cum</th>\n",
       "      <th>user_correct_answers_cum</th>\n",
       "      <th>user_avg_score_cum_part1</th>\n",
       "      <th>user_avg_score_cum_part2</th>\n",
       "      <th>user_avg_score_cum_part3</th>\n",
       "      <th>...</th>\n",
       "      <th>part</th>\n",
       "      <th>qstats_answered_correctly</th>\n",
       "      <th>qstats_prior_question_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_had_explanation</th>\n",
       "      <th>qstats_answered_correctly_knowing_having_not_had_explanation</th>\n",
       "      <th>user_personalized_qstat_knowing_had_explanation_or_not</th>\n",
       "      <th>already_seen</th>\n",
       "      <th>user_avg_score_cum_on_this_part</th>\n",
       "      <th>user_correct_answers_cum_on_this_part</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13522</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.913953</td>\n",
       "      <td>0.991860</td>\n",
       "      <td>0.913247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13521</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.808046</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.808535</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  content_type_id  prior_question_had_explanation  \\\n",
       "0          -1               -1                           False   \n",
       "1       13522                0                           False   \n",
       "2       13521                0                           False   \n",
       "\n",
       "   user_activity_cumcount  at_least_one_lesson  user_avg_score_cum  \\\n",
       "0                      -1                    0               0.499   \n",
       "1                       0                    0               0.499   \n",
       "2                       1                    0               0.800   \n",
       "\n",
       "   user_correct_answers_cum  user_avg_score_cum_part1  \\\n",
       "0                       0.0                     0.499   \n",
       "1                       0.0                     0.499   \n",
       "2                       0.8                     0.499   \n",
       "\n",
       "   user_avg_score_cum_part2  user_avg_score_cum_part3  ...  part  \\\n",
       "0                     0.499                     0.499  ...    -1   \n",
       "1                     0.499                     0.499  ...     5   \n",
       "2                     0.499                     0.499  ...     5   \n",
       "\n",
       "   qstats_answered_correctly  qstats_prior_question_had_explanation  \\\n",
       "0                  -1.000000                              -1.000000   \n",
       "1                   0.913953                               0.991860   \n",
       "2                   0.808046                               0.996552   \n",
       "\n",
       "   qstats_answered_correctly_knowing_having_had_explanation  \\\n",
       "0                                          -1.000000          \n",
       "1                                           0.913247          \n",
       "2                                           0.808535          \n",
       "\n",
       "   qstats_answered_correctly_knowing_having_not_had_explanation  \\\n",
       "0                                          -1.000000              \n",
       "1                                           1.000000              \n",
       "2                                           0.666667              \n",
       "\n",
       "   user_personalized_qstat_knowing_had_explanation_or_not  already_seen  \\\n",
       "0                                          -1.000000                 -1   \n",
       "1                                           1.000000                  0   \n",
       "2                                           0.666667                  0   \n",
       "\n",
       "   user_avg_score_cum_on_this_part  user_correct_answers_cum_on_this_part  \\\n",
       "0                           -1.000                                   -1.0   \n",
       "1                            0.499                                    0.0   \n",
       "2                            0.800                                    0.8   \n",
       "\n",
       "   answered_correctly  \n",
       "0                -1.0  \n",
       "1                 0.8  \n",
       "2                -1.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history=user_history_update(0,13521,qstats,user_history,prior_question_had_explanation=False)\n",
    "user_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:19.029642Z",
     "start_time": "2020-12-15T16:00:15.851Z"
    }
   },
   "outputs": [],
   "source": [
    "loop_length=1000\n",
    "question_selection_strategy='random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:19.040344Z",
     "start_time": "2020-12-15T16:00:15.855Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "### Initialize the user to None or starting level ###\n",
    "user_history=None\n",
    "\n",
    "for i in range(loop_length):\n",
    "    ### CHOIX DE LA QUESTION ###\n",
    "    if question_selection_strategy=='random':\n",
    "        next_question_id=random.choice(qstats.content_id.to_list())\n",
    "    \n",
    "    \n",
    "    user_history=user_history_update(0,\n",
    "                                     next_question_id,\n",
    "                                     qstats,\n",
    "                                     user_history,\n",
    "                                     prior_question_had_explanation=random.uniform(0, 1)>0.1)\n",
    "    \n",
    "    ### PREDICTION ###\n",
    "    user_history.iloc[-1,-1]\\\n",
    "        = my_pipeline.predict_proba(user_history[pipeline_features_list.feature.to_list()].iloc[-2:-1])[0,1]\n",
    "user_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:00:19.058248Z",
     "start_time": "2020-12-15T16:00:15.858Z"
    }
   },
   "outputs": [],
   "source": [
    "my_pipeline.predict_proba(user_history[pipeline_features_list.feature.to_list()].iloc[-2:-1])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:33:37.374225Z",
     "start_time": "2020-12-15T15:33:37.341583Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:56:21.658484Z",
     "start_time": "2020-12-15T15:56:21.625798Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-09782e358892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'hefibef'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdico\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only recognize index or columns for orient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m     def to_numpy(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dico = {\n",
    "    'bonheur':2,\n",
    "    'heheh':3,\n",
    "    'hefibef':5\n",
    "}\n",
    "df = pd.DataFrame.from_dict(dico)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
